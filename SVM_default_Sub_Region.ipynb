{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier: Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load & Inspect Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Country</th>\n",
       "      <th>Region</th>\n",
       "      <th>Sub_Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.161286</td>\n",
       "      <td>7.835325</td>\n",
       "      <td>2.911583</td>\n",
       "      <td>0.984049</td>\n",
       "      <td>-1.499546</td>\n",
       "      <td>-2.094097</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>-1.205671</td>\n",
       "      <td>1.849122</td>\n",
       "      <td>-0.425598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.174878</td>\n",
       "      <td>-1.089543</td>\n",
       "      <td>-0.668840</td>\n",
       "      <td>-0.914772</td>\n",
       "      <td>-0.836250</td>\n",
       "      <td>-15.75</td>\n",
       "      <td>-47.95</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>South America</td>\n",
       "      <td>South America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.225763</td>\n",
       "      <td>-0.094169</td>\n",
       "      <td>-0.603646</td>\n",
       "      <td>0.497745</td>\n",
       "      <td>0.874036</td>\n",
       "      <td>0.290280</td>\n",
       "      <td>-0.077659</td>\n",
       "      <td>-0.887385</td>\n",
       "      <td>0.432062</td>\n",
       "      <td>-0.093963</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.157189</td>\n",
       "      <td>0.380951</td>\n",
       "      <td>1.088478</td>\n",
       "      <td>-0.123595</td>\n",
       "      <td>1.391141</td>\n",
       "      <td>14.91</td>\n",
       "      <td>-23.51</td>\n",
       "      <td>Cabo Verde</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Western Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.692525</td>\n",
       "      <td>-0.517801</td>\n",
       "      <td>-0.788035</td>\n",
       "      <td>1.214351</td>\n",
       "      <td>-0.907214</td>\n",
       "      <td>0.880213</td>\n",
       "      <td>0.406899</td>\n",
       "      <td>-0.694895</td>\n",
       "      <td>-0.901869</td>\n",
       "      <td>-1.701574</td>\n",
       "      <td>...</td>\n",
       "      <td>2.718442</td>\n",
       "      <td>0.972919</td>\n",
       "      <td>2.081069</td>\n",
       "      <td>1.375763</td>\n",
       "      <td>1.063847</td>\n",
       "      <td>12.65</td>\n",
       "      <td>-8.00</td>\n",
       "      <td>Mali</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Western Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.735562</td>\n",
       "      <td>-0.684055</td>\n",
       "      <td>2.058215</td>\n",
       "      <td>0.716328</td>\n",
       "      <td>-0.011393</td>\n",
       "      <td>0.805396</td>\n",
       "      <td>1.497982</td>\n",
       "      <td>0.114752</td>\n",
       "      <td>0.692847</td>\n",
       "      <td>0.052377</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.020687</td>\n",
       "      <td>-0.751380</td>\n",
       "      <td>-0.385005</td>\n",
       "      <td>-0.012326</td>\n",
       "      <td>-0.392197</td>\n",
       "      <td>9.03</td>\n",
       "      <td>38.74</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Eastern Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.570272</td>\n",
       "      <td>0.273157</td>\n",
       "      <td>-0.279214</td>\n",
       "      <td>0.083456</td>\n",
       "      <td>1.049331</td>\n",
       "      <td>-0.869295</td>\n",
       "      <td>-0.265858</td>\n",
       "      <td>-0.401676</td>\n",
       "      <td>-0.872639</td>\n",
       "      <td>1.147483</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190488</td>\n",
       "      <td>0.306974</td>\n",
       "      <td>0.119658</td>\n",
       "      <td>0.271838</td>\n",
       "      <td>1.289783</td>\n",
       "      <td>34.03</td>\n",
       "      <td>-6.85</td>\n",
       "      <td>Morocco</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Northern Africa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  7.161286  7.835325  2.911583  0.984049 -1.499546 -2.094097  0.576000   \n",
       "1  0.225763 -0.094169 -0.603646  0.497745  0.874036  0.290280 -0.077659   \n",
       "2 -0.692525 -0.517801 -0.788035  1.214351 -0.907214  0.880213  0.406899   \n",
       "3 -0.735562 -0.684055  2.058215  0.716328 -0.011393  0.805396  1.497982   \n",
       "4  0.570272  0.273157 -0.279214  0.083456  1.049331 -0.869295 -0.265858   \n",
       "\n",
       "          7         8         9  ...        63        64        65        66  \\\n",
       "0 -1.205671  1.849122 -0.425598  ... -0.174878 -1.089543 -0.668840 -0.914772   \n",
       "1 -0.887385  0.432062 -0.093963  ... -0.157189  0.380951  1.088478 -0.123595   \n",
       "2 -0.694895 -0.901869 -1.701574  ...  2.718442  0.972919  2.081069  1.375763   \n",
       "3  0.114752  0.692847  0.052377  ... -1.020687 -0.751380 -0.385005 -0.012326   \n",
       "4 -0.401676 -0.872639  1.147483  ... -0.190488  0.306974  0.119658  0.271838   \n",
       "\n",
       "         67  Latitude  Longitude     Country         Region       Sub_Region  \n",
       "0 -0.836250    -15.75     -47.95      Brazil  South America    South America  \n",
       "1  1.391141     14.91     -23.51  Cabo Verde         Africa   Western Africa  \n",
       "2  1.063847     12.65      -8.00        Mali         Africa   Western Africa  \n",
       "3 -0.392197      9.03      38.74    Ethiopia         Africa   Eastern Africa  \n",
       "4  1.289783     34.03      -6.85     Morocco         Africa  Northern Africa  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read cleaned data into pandas & create dataframe\n",
    "df = pd.read_csv(os.path.join(\".\", \"Cleaned_Data\", \"default.csv\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1059 entries, 0 to 1058\n",
      "Data columns (total 73 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   0           1059 non-null   float64\n",
      " 1   1           1059 non-null   float64\n",
      " 2   2           1059 non-null   float64\n",
      " 3   3           1059 non-null   float64\n",
      " 4   4           1059 non-null   float64\n",
      " 5   5           1059 non-null   float64\n",
      " 6   6           1059 non-null   float64\n",
      " 7   7           1059 non-null   float64\n",
      " 8   8           1059 non-null   float64\n",
      " 9   9           1059 non-null   float64\n",
      " 10  10          1059 non-null   float64\n",
      " 11  11          1059 non-null   float64\n",
      " 12  12          1059 non-null   float64\n",
      " 13  13          1059 non-null   float64\n",
      " 14  14          1059 non-null   float64\n",
      " 15  15          1059 non-null   float64\n",
      " 16  16          1059 non-null   float64\n",
      " 17  17          1059 non-null   float64\n",
      " 18  18          1059 non-null   float64\n",
      " 19  19          1059 non-null   float64\n",
      " 20  20          1059 non-null   float64\n",
      " 21  21          1059 non-null   float64\n",
      " 22  22          1059 non-null   float64\n",
      " 23  23          1059 non-null   float64\n",
      " 24  24          1059 non-null   float64\n",
      " 25  25          1059 non-null   float64\n",
      " 26  26          1059 non-null   float64\n",
      " 27  27          1059 non-null   float64\n",
      " 28  28          1059 non-null   float64\n",
      " 29  29          1059 non-null   float64\n",
      " 30  30          1059 non-null   float64\n",
      " 31  31          1059 non-null   float64\n",
      " 32  32          1059 non-null   float64\n",
      " 33  33          1059 non-null   float64\n",
      " 34  34          1059 non-null   float64\n",
      " 35  35          1059 non-null   float64\n",
      " 36  36          1059 non-null   float64\n",
      " 37  37          1059 non-null   float64\n",
      " 38  38          1059 non-null   float64\n",
      " 39  39          1059 non-null   float64\n",
      " 40  40          1059 non-null   float64\n",
      " 41  41          1059 non-null   float64\n",
      " 42  42          1059 non-null   float64\n",
      " 43  43          1059 non-null   float64\n",
      " 44  44          1059 non-null   float64\n",
      " 45  45          1059 non-null   float64\n",
      " 46  46          1059 non-null   float64\n",
      " 47  47          1059 non-null   float64\n",
      " 48  48          1059 non-null   float64\n",
      " 49  49          1059 non-null   float64\n",
      " 50  50          1059 non-null   float64\n",
      " 51  51          1059 non-null   float64\n",
      " 52  52          1059 non-null   float64\n",
      " 53  53          1059 non-null   float64\n",
      " 54  54          1059 non-null   float64\n",
      " 55  55          1059 non-null   float64\n",
      " 56  56          1059 non-null   float64\n",
      " 57  57          1059 non-null   float64\n",
      " 58  58          1059 non-null   float64\n",
      " 59  59          1059 non-null   float64\n",
      " 60  60          1059 non-null   float64\n",
      " 61  61          1059 non-null   float64\n",
      " 62  62          1059 non-null   float64\n",
      " 63  63          1059 non-null   float64\n",
      " 64  64          1059 non-null   float64\n",
      " 65  65          1059 non-null   float64\n",
      " 66  66          1059 non-null   float64\n",
      " 67  67          1059 non-null   float64\n",
      " 68  Latitude    1059 non-null   float64\n",
      " 69  Longitude   1059 non-null   float64\n",
      " 70  Country     1059 non-null   object \n",
      " 71  Region      1059 non-null   object \n",
      " 72  Sub_Region  1059 non-null   object \n",
      "dtypes: float64(70), object(3)\n",
      "memory usage: 604.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Determine data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>Sub_Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.161286</td>\n",
       "      <td>7.835325</td>\n",
       "      <td>2.911583</td>\n",
       "      <td>0.984049</td>\n",
       "      <td>-1.499546</td>\n",
       "      <td>-2.094097</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>-1.205671</td>\n",
       "      <td>1.849122</td>\n",
       "      <td>-0.425598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043610</td>\n",
       "      <td>-1.504263</td>\n",
       "      <td>0.351267</td>\n",
       "      <td>-1.018726</td>\n",
       "      <td>-0.174878</td>\n",
       "      <td>-1.089543</td>\n",
       "      <td>-0.668840</td>\n",
       "      <td>-0.914772</td>\n",
       "      <td>-0.836250</td>\n",
       "      <td>South America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.225763</td>\n",
       "      <td>-0.094169</td>\n",
       "      <td>-0.603646</td>\n",
       "      <td>0.497745</td>\n",
       "      <td>0.874036</td>\n",
       "      <td>0.290280</td>\n",
       "      <td>-0.077659</td>\n",
       "      <td>-0.887385</td>\n",
       "      <td>0.432062</td>\n",
       "      <td>-0.093963</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.947933</td>\n",
       "      <td>-0.495712</td>\n",
       "      <td>-0.465077</td>\n",
       "      <td>-0.157861</td>\n",
       "      <td>-0.157189</td>\n",
       "      <td>0.380951</td>\n",
       "      <td>1.088478</td>\n",
       "      <td>-0.123595</td>\n",
       "      <td>1.391141</td>\n",
       "      <td>Western Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.692525</td>\n",
       "      <td>-0.517801</td>\n",
       "      <td>-0.788035</td>\n",
       "      <td>1.214351</td>\n",
       "      <td>-0.907214</td>\n",
       "      <td>0.880213</td>\n",
       "      <td>0.406899</td>\n",
       "      <td>-0.694895</td>\n",
       "      <td>-0.901869</td>\n",
       "      <td>-1.701574</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.556109</td>\n",
       "      <td>-0.637167</td>\n",
       "      <td>0.147260</td>\n",
       "      <td>0.217914</td>\n",
       "      <td>2.718442</td>\n",
       "      <td>0.972919</td>\n",
       "      <td>2.081069</td>\n",
       "      <td>1.375763</td>\n",
       "      <td>1.063847</td>\n",
       "      <td>Western Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.735562</td>\n",
       "      <td>-0.684055</td>\n",
       "      <td>2.058215</td>\n",
       "      <td>0.716328</td>\n",
       "      <td>-0.011393</td>\n",
       "      <td>0.805396</td>\n",
       "      <td>1.497982</td>\n",
       "      <td>0.114752</td>\n",
       "      <td>0.692847</td>\n",
       "      <td>0.052377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166616</td>\n",
       "      <td>-0.178325</td>\n",
       "      <td>-0.065059</td>\n",
       "      <td>-0.724247</td>\n",
       "      <td>-1.020687</td>\n",
       "      <td>-0.751380</td>\n",
       "      <td>-0.385005</td>\n",
       "      <td>-0.012326</td>\n",
       "      <td>-0.392197</td>\n",
       "      <td>Eastern Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.570272</td>\n",
       "      <td>0.273157</td>\n",
       "      <td>-0.279214</td>\n",
       "      <td>0.083456</td>\n",
       "      <td>1.049331</td>\n",
       "      <td>-0.869295</td>\n",
       "      <td>-0.265858</td>\n",
       "      <td>-0.401676</td>\n",
       "      <td>-0.872639</td>\n",
       "      <td>1.147483</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.500785</td>\n",
       "      <td>-0.919463</td>\n",
       "      <td>-0.667912</td>\n",
       "      <td>-0.820172</td>\n",
       "      <td>-0.190488</td>\n",
       "      <td>0.306974</td>\n",
       "      <td>0.119658</td>\n",
       "      <td>0.271838</td>\n",
       "      <td>1.289783</td>\n",
       "      <td>Northern Africa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  7.161286  7.835325  2.911583  0.984049 -1.499546 -2.094097  0.576000   \n",
       "1  0.225763 -0.094169 -0.603646  0.497745  0.874036  0.290280 -0.077659   \n",
       "2 -0.692525 -0.517801 -0.788035  1.214351 -0.907214  0.880213  0.406899   \n",
       "3 -0.735562 -0.684055  2.058215  0.716328 -0.011393  0.805396  1.497982   \n",
       "4  0.570272  0.273157 -0.279214  0.083456  1.049331 -0.869295 -0.265858   \n",
       "\n",
       "          7         8         9  ...        59        60        61        62  \\\n",
       "0 -1.205671  1.849122 -0.425598  ... -0.043610 -1.504263  0.351267 -1.018726   \n",
       "1 -0.887385  0.432062 -0.093963  ... -0.947933 -0.495712 -0.465077 -0.157861   \n",
       "2 -0.694895 -0.901869 -1.701574  ... -0.556109 -0.637167  0.147260  0.217914   \n",
       "3  0.114752  0.692847  0.052377  ...  0.166616 -0.178325 -0.065059 -0.724247   \n",
       "4 -0.401676 -0.872639  1.147483  ... -0.500785 -0.919463 -0.667912 -0.820172   \n",
       "\n",
       "         63        64        65        66        67       Sub_Region  \n",
       "0 -0.174878 -1.089543 -0.668840 -0.914772 -0.836250    South America  \n",
       "1 -0.157189  0.380951  1.088478 -0.123595  1.391141   Western Africa  \n",
       "2  2.718442  0.972919  2.081069  1.375763  1.063847   Western Africa  \n",
       "3 -1.020687 -0.751380 -0.385005 -0.012326 -0.392197   Eastern Africa  \n",
       "4 -0.190488  0.306974  0.119658  0.271838  1.289783  Northern Africa  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop all columns except inputs and desired output column\n",
    "dropped_column_list = ['Latitude', 'Longitude', 'Country', 'Region']\n",
    "df.drop(dropped_column_list, axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of unique entries in target column (this will be our y variable)\n",
    "df['Sub_Region'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Southern Asia                139\n",
       "Western Africa               124\n",
       "Southern Europe              118\n",
       "Northern Africa               99\n",
       "Western Asia                  93\n",
       "South-eastern Asia            91\n",
       "Eastern Asia                  84\n",
       "Eastern Africa                82\n",
       "Northern Europe               65\n",
       "Central Asia                  62\n",
       "South America                 36\n",
       "Caribbean                     22\n",
       "Eastern Europe                19\n",
       "Australia and New Zealand     14\n",
       "Central America               11\n",
       "Name: Sub_Region, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine number of entries per unique entry in target column\n",
    "df['Sub_Region'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Southern Asia                139\n",
       "Western Africa               124\n",
       "Southern Europe              118\n",
       "Northern Africa               99\n",
       "Western Asia                  93\n",
       "South-eastern Asia            91\n",
       "Eastern Asia                  84\n",
       "Eastern Africa                82\n",
       "Northern Europe               65\n",
       "Central Asia                  62\n",
       "South America                 36\n",
       "Caribbean                     22\n",
       "Eastern Europe                19\n",
       "Australia and New Zealand     14\n",
       "Central America               11\n",
       "Name: Sub_Region, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reformat data\n",
    "data = df.values\n",
    "X = data[:, 0:115]\n",
    "\n",
    "y = df['Sub_Region']\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encode Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9 13 13 ... 12  8  8]\n"
     ]
    }
   ],
   "source": [
    "# Label-encode data set\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y)\n",
    "encoded_y = label_encoder.transform(y)\n",
    "print(encoded_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# NOTE: Random state ensures that the splits that we generate are reproducible.Scikit-learn uses random permutations to \n",
    "# generate the splits.The random state that you provide is used as a seed to the random number generator. This ensures\n",
    "# that the random numbers are generated in the same order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the Shape of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Shape: (794, 69)\n",
      "y_train Shape: (794,)\n",
      "X_test Shape: (265, 69)\n",
      "y_test Shape: (265,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train Shape:', X_train.shape)\n",
    "print('y_train Shape:', y_train.shape)\n",
    "print('X_test Shape:', X_test.shape)\n",
    "print('y_test Shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin Support Vector Machine (SVM) linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM or Support Vector Machine is a linear model for classification and regression problems. It can solve linear and \n",
    "# non-linear problems and work well for many practical problems. The idea of SVM is simple: The algorithm creates a line\n",
    "# or a hyperplane which separates the data into classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Southern Asia'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-c12b32666c11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonML\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    160\u001b[0m             X, y = self._validate_data(X, y, dtype=np.float64,\n\u001b[0;32m    161\u001b[0m                                        \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m                                        accept_large_sparse=False)\n\u001b[0m\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonML\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonML\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonML\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    800\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 802\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    803\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonML\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonML\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    596\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonML\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Southern Asia'"
     ]
    }
   ],
   "source": [
    "# Import SVM\n",
    "from sklearn.svm import SVC \n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Accuracy\n",
    "print('Test Acc: %.3f' % model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOW TO INTERPRET CLASSIFICATION REPORT\n",
    "\n",
    "# PRECISION\n",
    "# Precision is a measure of a classifier’s exactness. It is the fraction of predicted positives events that are actually\n",
    "# positive. For each class, it is defined as the ratio of true positives to the sum of true & false positives. Said \n",
    "# another way, “for all instances classified positive, what percent was correct?\n",
    "\n",
    "# RECALL\n",
    "# Recall (also known as sensitivity) is the fraction of positives events that you predicted correctly.\n",
    "# Recall is a measure of the classifier’s completeness; the ability of a classifier to correctly find all positive \n",
    "# instances. For each class, it is defined as the ratio of true positives to the sum of true positives & false \n",
    "# negatives. Said another way, “for all instances that were actually positive, what percent was classified correctly?”\n",
    "\n",
    "# F1 SCORE\n",
    "# The f1 score is the harmonic mean of recall and precision, with a higher score as a better model.\n",
    "# The F1 score is a weighted harmonic mean of precision and recall such that the best score is 1.0 and the worst is 0.0.\n",
    "# Generally speaking, F1 scores are lower than accuracy measures as they embed precision and recall into their \n",
    "# computation. As a rule of thumb, the weighted average of F1 should be used to compare classifier models, not global \n",
    "# accuracy.\n",
    "\n",
    "# SUPPORT\n",
    "# Support is the number of actual occurrences of the class in the specified dataset. Imbalanced support in the training\n",
    "# data may indicate structural weaknesses in the reported scores of the classifier and could indicate the need for \n",
    "# stratified sampling or rebalancing. Support doesn’t change between models, instead it diagnoses the evaluation process.\n",
    "\n",
    "# ACCURACY\n",
    "# The most common metric for classification is Accuracy, which is the fraction of samples predicted correctly.  \n",
    "# But Accuracy is not always the best metric to use to assess classification models. \n",
    "\n",
    "# MACRO AVERAGE\n",
    "# Macro Average takes the function to compute f1 for each label, and returns the average without considering the \n",
    "# proportion for each label in the dataset. \n",
    "\n",
    "# WEIGHTED AVERAGE\n",
    "# Weighted Average takes the function to compute f1 for each label, and returns the average considering the proportion\n",
    "# for each label in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate & print classification report\n",
    "from sklearn.metrics import classification_report\n",
    "predictions = model.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "true = np.random.randint(0, 15, size=100)\n",
    "pred = np.random.randint(0, 15, size=100)\n",
    "labels = np.arange(15)\n",
    "target_names = list(\"ABCDEFGHIJKLMNO\")\n",
    "\n",
    "clf_report = classification_report(true,\n",
    "                                   pred,\n",
    "                                   labels=labels,\n",
    "                                   target_names=target_names,\n",
    "                                   output_dict=True)\n",
    "\n",
    "# .iloc[:-1, :] to exclude support\n",
    "sns.heatmap(pd.DataFrame(clf_report).iloc[:-1, :].T, annot=True)\n",
    "visualizer.show(outpath='./images/Chromatc Sub-Region - Parallel Coordinates for 115 Features.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.features import ParallelCoordinates\n",
    "\n",
    "visualizer = ParallelCoordinates()\n",
    "visualizer.fit_transform(X, y)\n",
    "visualizer.show()\n",
    "visualizer.show(outpath='./images/Chromatc Sub-Region - Parallel Coordinates for 115 Features.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SVM classifier\n",
    "clf = svm.SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get support vectors\n",
    "support_vectors = clf.support_vectors_\n",
    "\n",
    "# Visualize support vectors\n",
    "plt.scatter(X_train[:,0], X_train[:,1])\n",
    "plt.scatter(support_vectors[:,0], support_vectors[:,1], color='red')\n",
    "plt.title('Linearly separable data with support vectors')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.savefig('./images/Chromatc Sub-Region - Linearly Separable Data with Support Vectors.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Error Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A prediction error plot shows the actual targets from the dataset against the predicted values generated by our model.\n",
    "# This allows us to see how much variance is in the model. We can diagnose the regression models using this \n",
    "# plot by comparing against the 45 degree line, where the prediction exactly matches the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from yellowbrick.datasets import load_concrete\n",
    "from yellowbrick.regressor import PredictionError\n",
    "\n",
    "# Load a regression dataset\n",
    "X, y = load_concrete()\n",
    "\n",
    "# Create the train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate the linear model and visualizer\n",
    "model = Lasso()\n",
    "visualizer = PredictionError(model)\n",
    "\n",
    "visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "visualizer.show()                 # Finalize and render the figure\n",
    "visualizer.show(outpath='./images/Chromatc Sub-Region - Prediction Error.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threshold Plot for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression is used for predicting the continuous dependent variable using a given set of independent features\n",
    "# whereas Logistic Regression is used to predict the categorical. Linear regression is used to solve regression problems\n",
    "# whereas logistic regression is used to solve classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from yellowbrick.classifier import DiscriminationThreshold\n",
    "from yellowbrick.datasets import load_spam\n",
    "\n",
    "# Load a binary classification dataset\n",
    "X, y = load_spam()\n",
    "\n",
    "# Instantiate the classification model and visualizer\n",
    "model = LogisticRegression(multi_class=\"auto\", solver=\"liblinear\")\n",
    "visualizer = DiscriminationThreshold(model)\n",
    "\n",
    "visualizer.fit(X, y)        # Fit the data to the visualizer\n",
    "visualizer.show()           # Finalize and render the figure\n",
    "visualizer.show(outpath='./images/Chromatc Sub-Region - Threshold Plot for LogisticRegression.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from neupy import algorithms\n",
    "from sklearn.base import BaseEstimator\n",
    "from yellowbrick.datasets import load_occupancy\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class PNNWrapper(algorithms.PNN, BaseEstimator):\n",
    "    \"\"\"\n",
    "    The PNN wrapper implements BaseEstimator and allows the classification\n",
    "    report to score the model and understand the learned classes.\n",
    "    \"\"\"\n",
    "\n",
    "    @property\n",
    "    def classes_(self):\n",
    "        return self.classes\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        y_hat = self.predict(X_test)\n",
    "        return metrics.accuracy_score(y_test, y_hat)\n",
    "\n",
    "\n",
    "# Load the binary classification dataset \n",
    "X, y = load_occupancy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Create and train the PNN model using the sklearn wrapper\n",
    "model = PNNWrapper(std=0.1, verbose=True, batch_size=1059)\n",
    "model.train(X_train, y_train)\n",
    "\n",
    "# Create the classification report\n",
    "viz = ClassificationReport(\n",
    "    model, \n",
    "    support=True, \n",
    "    classes=[\"not occupied\", \"occupied\"], \n",
    "    is_fitted=True, \n",
    "    force_model=True, \n",
    "    title=\"PNN\"\n",
    ")\n",
    "\n",
    "# Score the report and show it\n",
    "viz.score(X_test, y_test)\n",
    "viz.show()\n",
    "viz.show(outpath='./images/Chromatc Sub-Region - PNN Wrapper.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
